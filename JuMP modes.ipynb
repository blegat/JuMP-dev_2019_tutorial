{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JuMP has a Direct, an Automatic and a Manual mode. In this tutorial, we look at the difference between these modes.\n",
    "\n",
    "We illustrate this different modes using the CSDP interface. CSDP supports problems in the following format\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\text{maximize} \\quad \\langle C, X\\rangle\\\\\n",
    "    \\langle A_i, X\\rangle & = b_i\\\\\n",
    "          X & \\succeq 0\n",
    "\\end{align*}\n",
    "$$\n",
    "where `X` is a block-diagonal matrix.\n",
    "\n",
    "The problem is inputed as follows:\n",
    "1. Provide number of linear constraints and list of blocks size.\n",
    "2. Provide the list of nonzero entries of `C`, `A_i` and values of `b_i`.\n",
    "\n",
    "Consider the problem of finding the maximum $\\alpha$ such that $x^2 + \\alpha x + 1$ is nonnegative for all $x \\in \\mathbb{R}$.\n",
    "It can be written as an SDP as follows:\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\text{maximize} \\quad 2X_{1, 2}\\\\\n",
    "    X_{1, 1} & = 1\\\\\n",
    "    X_{2, 2} & = 1\\\\\n",
    "    X & \\succeq 0\n",
    "\\end{align*}\n",
    "$$\n",
    "The CSDP form is\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\text{maximize} \\quad \\langle \\begin{pmatrix}0 & 1\\\\1 & 0\\end{pmatrix}, X\\rangle\\\\\n",
    "    \\langle \\begin{pmatrix}1 & 0\\\\0 & 0\\end{pmatrix}, X\\rangle & = 1\\\\\n",
    "    \\langle \\begin{pmatrix}0 & 0\\\\0 & 1\\end{pmatrix}, X\\rangle & = 1\\\\\n",
    "          X & \\succeq 0\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "## Caching Optimizer\n",
    "\n",
    "The CSDP interface does not support loading the problem incrementally as it requires having the list of blocks and number of constraints before loading any constraint data.\n",
    "Therefore, adding variables or constraints through `MOI.add_variable` and `MOI.add_constraint` is not supported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "MathOptInterface.AddVariableNotAllowed",
     "evalue": "MathOptInterface.AddVariableNotAllowed: Adding variables cannot be performed. You may want to use a `CachingOptimizer` in `AUTOMATIC` mode or you may need to call `reset_optimizer` before doing this operation if the `CachingOptimizer` is in `MANUAL` mode.",
     "output_type": "error",
     "traceback": [
      "MathOptInterface.AddVariableNotAllowed: Adding variables cannot be performed. You may want to use a `CachingOptimizer` in `AUTOMATIC` mode or you may need to call `reset_optimizer` before doing this operation if the `CachingOptimizer` is in `MANUAL` mode.",
      "",
      "Stacktrace:",
      " [1] add_variable(::SemidefiniteOptInterface.SOItoMOIBridge{Float64,CSDP.SDOptimizer}) at /home/blegat/.julia/dev/MathOptInterface/src/variables.jl:35",
      " [2] VariableRef(::Model) at /home/blegat/.julia/packages/JuMP/HmKx8/src/variables.jl:200",
      " [3] add_variable(::Model, ::ScalarVariable{Float64,Float64,Float64,Float64}, ::String) at /home/blegat/.julia/packages/JuMP/HmKx8/src/variables.jl:743",
      " [4] top-level scope at /home/blegat/.julia/packages/JuMP/HmKx8/src/macros.jl:300",
      " [5] top-level scope at In[79]:5"
     ]
    }
   ],
   "source": [
    "import CSDP\n",
    "optimizer = CSDP.Optimizer()\n",
    "using JuMP\n",
    "model = direct_model(optimizer)\n",
    "@variable(model, α)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem needs to be cached and loaded at once so that the CSDP MOI wrapper can read the whole problem, initialize CSDP with the number of constraints and list of blocks, and then load the coefficients into `C`, `A_i` and `b_i`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A JuMP Model\n",
      "Feasibility problem with:\n",
      "Variables: 0\n",
      "Model mode: AUTOMATIC\n",
      "CachingOptimizer state: ATTACHED_OPTIMIZER\n",
      "Solver name: CSDP"
     ]
    }
   ],
   "source": [
    "cached = MOIU.CachingOptimizer(JuMP._MOIModel{Float64}(), optimizer)\n",
    "model = direct_model(cached)\n",
    "show(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see below, JuMP believes we have created the model in `AUTOMATIC` mode because we have added a cache."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×2 LinearAlgebra.Symmetric{VariableRef,Array{VariableRef,2}}:\n",
       " X[1,1]  X[1,2]\n",
       " X[1,2]  X[2,2]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@variable(model, X[1:2, 1:2], PSD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A JuMP Model\n",
      "Feasibility problem with:\n",
      "Variables: 3\n",
      "`Array{VariableRef,1}`-in-`MathOptInterface.PositiveSemidefiniteConeTriangle`: 1 constraint\n",
      "Model mode: AUTOMATIC\n",
      "CachingOptimizer state: EMPTY_OPTIMIZER\n",
      "Solver name: CSDP\n",
      "Names registered in the model: X"
     ]
    }
   ],
   "source": [
    "show(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see above that the model was detached because the CSDP optimizer does not support `add_constraint`, the model will be copied all at once at `optimize!`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$ X_{1,1} = 1.0 $"
      ],
      "text/plain": [
       "X[1,1] = 1.0"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@constraint(model, X[1, 1] == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$ X_{2,2} = 1.0 $"
      ],
      "text/plain": [
       "X[2,2] = 1.0"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@constraint(model, X[2, 2] == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$$ 2 X_{1,2} $$"
      ],
      "text/plain": [
       "2 X[1,2]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@objective(model, Max, 2X[1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSDP 6.2.0\n",
      "Iter:  0 Ap: 0.00e+00 Pobj:  0.0000000e+00 Ad: 0.00e+00 Dobj:  0.0000000e+00 \n",
      "Iter:  1 Ap: 1.00e+00 Pobj:  2.3431458e-01 Ad: 1.00e+00 Dobj:  3.2435027e+01 \n",
      "Iter:  2 Ap: 1.00e+00 Pobj:  3.5817600e-01 Ad: 1.00e+00 Dobj:  1.6458531e+01 \n",
      "Iter:  3 Ap: 1.00e+00 Pobj:  6.3421738e-01 Ad: 1.00e+00 Dobj:  8.6843940e+00 \n",
      "Iter:  4 Ap: 1.00e+00 Pobj:  1.0638920e+00 Ad: 1.00e+00 Dobj:  5.0889793e+00 \n",
      "Iter:  5 Ap: 1.00e+00 Pobj:  1.4516765e+00 Ad: 1.00e+00 Dobj:  3.4642192e+00 \n",
      "Iter:  6 Ap: 1.00e+00 Pobj:  1.6669906e+00 Ad: 1.00e+00 Dobj:  2.6732609e+00 \n",
      "Iter:  7 Ap: 1.00e+00 Pobj:  1.8020927e+00 Ad: 1.00e+00 Dobj:  2.3052268e+00 \n",
      "Iter:  8 Ap: 1.00e+00 Pobj:  1.8891872e+00 Ad: 1.00e+00 Dobj:  2.1407533e+00 \n",
      "Iter:  9 Ap: 1.00e+00 Pobj:  1.9410015e+00 Ad: 1.00e+00 Dobj:  2.0667836e+00 \n",
      "Iter: 10 Ap: 1.00e+00 Pobj:  1.9999978e+00 Ad: 9.00e-01 Dobj:  2.0066746e+00 \n",
      "Iter: 11 Ap: 1.00e+00 Pobj:  2.0000000e+00 Ad: 9.00e-01 Dobj:  2.0006657e+00 \n",
      "Iter: 12 Ap: 1.00e+00 Pobj:  1.9998331e+00 Ad: 1.00e+00 Dobj:  2.0001649e+00 \n",
      "Iter: 13 Ap: 1.00e+00 Pobj:  1.9999917e+00 Ad: 1.00e+00 Dobj:  2.0000063e+00 \n",
      "Iter: 14 Ap: 1.00e+00 Pobj:  1.9999996e+00 Ad: 1.00e+00 Dobj:  2.0000000e+00 \n",
      "Iter: 15 Ap: 1.00e+00 Pobj:  2.0000000e+00 Ad: 1.00e+00 Dobj:  2.0000000e+00 \n"
     ]
    }
   ],
   "source": [
    "optimize!(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A JuMP Model\n",
      "Maximization problem with:\n",
      "Variables: 3\n",
      "Objective function type: GenericAffExpr{Float64,VariableRef}\n",
      "`GenericAffExpr{Float64,VariableRef}`-in-`MathOptInterface.EqualTo{Float64}`: 2 constraints\n",
      "`Array{VariableRef,1}`-in-`MathOptInterface.PositiveSemidefiniteConeTriangle`: 1 constraint\n",
      "Model mode: AUTOMATIC\n",
      "CachingOptimizer state: ATTACHED_OPTIMIZER\n",
      "Solver name: CSDP\n",
      "Names registered in the model: X"
     ]
    }
   ],
   "source": [
    "show(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see above, CSDP has been attached in just before calling `MOI.optimize!`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×2 Array{Float64,2}:\n",
       " 1.0  1.0\n",
       " 1.0  1.0"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value.(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9999999791293397"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objective_value(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constraint Bridges\n",
    "\n",
    "Now suppose we would like to maximize $\\alpha$ such that $\\beta x^2 + \\alpha x + \\gamma$ is nonnegative for all $x \\in \\mathbb{R}$ and $\\beta + \\gamma \\le 2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "ErrorException",
     "evalue": "Constraints of type MathOptInterface.ScalarAffineFunction{Float64}-in-MathOptInterface.LessThan{Float64} are not supported by the solver, try using `bridge_constraints=true` in the `JuMP.Model` constructor if you believe the constraint can be reformulated to constraints supported by the solver.",
     "output_type": "error",
     "traceback": [
      "Constraints of type MathOptInterface.ScalarAffineFunction{Float64}-in-MathOptInterface.LessThan{Float64} are not supported by the solver, try using `bridge_constraints=true` in the `JuMP.Model` constructor if you believe the constraint can be reformulated to constraints supported by the solver.",
      "",
      "Stacktrace:",
      " [1] moi_add_constraint(::MathOptInterface.Utilities.CachingOptimizer{SemidefiniteOptInterface.SOItoMOIBridge{Float64,CSDP.SDOptimizer},JuMP._MOIModel{Float64}}, ::MathOptInterface.ScalarAffineFunction{Float64}, ::MathOptInterface.LessThan{Float64}) at /home/blegat/.julia/packages/JuMP/HmKx8/src/constraints.jl:371",
      " [2] add_constraint(::Model, ::ScalarConstraint{GenericAffExpr{Float64,VariableRef},MathOptInterface.LessThan{Float64}}, ::String) at /home/blegat/.julia/packages/JuMP/HmKx8/src/constraints.jl:385",
      " [3] top-level scope at /home/blegat/.julia/packages/JuMP/HmKx8/src/macros.jl:621",
      " [4] top-level scope at In[90]:4"
     ]
    }
   ],
   "source": [
    "MOI.empty!(cached)\n",
    "model = direct_model(cached)\n",
    "@variable(model, X[1:2, 1:2], PSD)\n",
    "@constraint(model, X[1, 1] + X[2, 2] ≤ 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As pointed out by the error message, the solver does not support inequality between scalar affine function.\n",
    "However, as it supports equality between affine functions and nonnegative variables (1x1 blocks in the `X` matrix), it could reformulate it into an equivalent form supported by the solver by adding a slack variable.\n",
    "This is achieved by the `ScalarSlackBridge`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$ X_{1,1} + X_{2,2} \\leq 2.0 $"
      ],
      "text/plain": [
       "X[1,1] + X[2,2] ≤ 2.0"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MOI.empty!(cached)\n",
    "bridged = MOI.Bridges.full_bridge_optimizer(cached, Float64)\n",
    "model = direct_model(bridged)\n",
    "@variable(model, X[1:2, 1:2], PSD)\n",
    "@constraint(model, X[1, 1] + X[2, 2] ≤ 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSDP 6.2.0\n",
      "Iter:  0 Ap: 0.00e+00 Pobj:  0.0000000e+00 Ad: 0.00e+00 Dobj:  0.0000000e+00 \n",
      "Iter:  1 Ap: 1.00e+00 Pobj:  1.6905989e-01 Ad: 1.00e+00 Dobj:  3.0908574e+01 \n",
      "Iter:  2 Ap: 1.00e+00 Pobj:  3.4998523e-01 Ad: 9.00e-01 Dobj:  3.4058426e+00 \n",
      "Iter:  3 Ap: 1.00e+00 Pobj:  1.6203778e+00 Ad: 1.00e+00 Dobj:  3.1483057e+00 \n",
      "Iter:  4 Ap: 1.00e+00 Pobj:  1.6492373e+00 Ad: 1.00e+00 Dobj:  2.4132005e+00 \n",
      "Iter:  5 Ap: 1.00e+00 Pobj:  1.7961213e+00 Ad: 1.00e+00 Dobj:  2.1781021e+00 \n",
      "Iter:  6 Ap: 9.00e-01 Pobj:  1.9795801e+00 Ad: 9.00e-01 Dobj:  2.0177767e+00 \n",
      "Iter:  7 Ap: 9.00e-01 Pobj:  1.9979580e+00 Ad: 1.00e+00 Dobj:  1.9999984e+00 \n",
      "Iter:  8 Ap: 9.00e-01 Pobj:  1.9997958e+00 Ad: 1.00e+00 Dobj:  1.9999984e+00 \n",
      "Iter:  9 Ap: 5.12e-01 Pobj:  1.9998934e+00 Ad: 1.00e+00 Dobj:  2.0000052e+00 \n",
      "Iter: 10 Ap: 1.00e+00 Pobj:  1.9999995e+00 Ad: 1.00e+00 Dobj:  1.9999998e+00 \n",
      "Iter: 11 Ap: 1.00e+00 Pobj:  2.0000000e+00 Ad: 1.00e+00 Dobj:  2.0000000e+00 \n"
     ]
    }
   ],
   "source": [
    "@objective(model, Max, 2X[1, 2])\n",
    "optimize!(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×2 Array{Float64,2}:\n",
       " 1.0  1.0\n",
       " 1.0  1.0"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value.(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model cache\n",
    "\n",
    "Suppose now that we would like to solve the same problem with SDPA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "ename": "ErrorException",
     "evalue": "The `set_optimizer` function is not supported in DIRECT mode.",
     "output_type": "error",
     "traceback": [
      "The `set_optimizer` function is not supported in DIRECT mode.",
      "",
      "Stacktrace:",
      " [1] error_if_direct_mode at /home/blegat/.julia/packages/JuMP/HmKx8/src/optimizer_interface.jl:8 [inlined]",
      " [2] #set_optimizer#76(::Bool, ::Function, ::Model, ::OptimizerFactory) at /home/blegat/.julia/packages/JuMP/HmKx8/src/optimizer_interface.jl:37",
      " [3] set_optimizer(::Model, ::OptimizerFactory) at /home/blegat/.julia/packages/JuMP/HmKx8/src/optimizer_interface.jl:37",
      " [4] top-level scope at In[94]:2"
     ]
    }
   ],
   "source": [
    "import SDPA\n",
    "set_optimizer(model, with_optimizer(SDPA.Optimizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `set_optimizer` function is not supported in DIRECT mode because changing the optimizer would invalidate the variables and constraint references hold by the user.\n",
    "Moreover, we cannot just reset the optimizer in `cached` since SDPA might need different bridges, and changing the bridges might change the indices of constraints.\n",
    "So resolve this issue, we use a cache of the model before it is bridged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A JuMP Model\n",
      "Maximization problem with:\n",
      "Variables: 3\n",
      "Objective function type: GenericAffExpr{Float64,VariableRef}\n",
      "`Array{VariableRef,1}`-in-`MathOptInterface.PositiveSemidefiniteConeTriangle`: 1 constraint\n",
      "`GenericAffExpr{Float64,VariableRef}`-in-`MathOptInterface.LessThan{Float64}`: 1 constraint\n",
      "Model mode: DIRECT\n",
      "Solver name: CSDP\n",
      "Names registered in the model: X"
     ]
    }
   ],
   "source": [
    "show(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see above, the model is considered to be in DIRECT mode because type of the backend is `LazyBridgeOptimizer`, not `CachingOptimizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A JuMP Model\n",
      "Feasibility problem with:\n",
      "Variables: 0\n",
      "Model mode: AUTOMATIC\n",
      "CachingOptimizer state: EMPTY_OPTIMIZER\n",
      "Solver name: CSDP"
     ]
    }
   ],
   "source": [
    "MOI.empty!(bridged)\n",
    "backend = MOIU.CachingOptimizer(JuMP._MOIModel{Float64}(), MOIU.AUTOMATIC)\n",
    "MOIU.reset_optimizer(backend, bridged)\n",
    "model = direct_model(backend)\n",
    "show(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen above, JuMP believes we created the model in AUTOMATIC mode because we created a cache for the unbridged model in `MOIU.AUTOMATIC` mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A JuMP Model\n",
      "Maximization problem with:\n",
      "Variables: 3\n",
      "Objective function type: GenericAffExpr{Float64,VariableRef}\n",
      "`GenericAffExpr{Float64,VariableRef}`-in-`MathOptInterface.LessThan{Float64}`: 1 constraint\n",
      "`Array{VariableRef,1}`-in-`MathOptInterface.PositiveSemidefiniteConeTriangle`: 1 constraint\n",
      "Model mode: AUTOMATIC\n",
      "CachingOptimizer state: EMPTY_OPTIMIZER\n",
      "Solver name: CSDP\n",
      "Names registered in the model: X"
     ]
    }
   ],
   "source": [
    "@variable(model, X[1:2, 1:2], PSD)\n",
    "cref = @constraint(model, X[1, 1] + X[2, 2] ≤ 2)\n",
    "@objective(model, Max, 2X[1, 2])\n",
    "show(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see above, the inequality between affine expressions is not bridged in the backend model (we may switch to an optimizer supporting this type of constraints!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSDP 6.2.0\n",
      "Iter:  0 Ap: 0.00e+00 Pobj:  0.0000000e+00 Ad: 0.00e+00 Dobj:  0.0000000e+00 \n",
      "Iter:  1 Ap: 1.00e+00 Pobj:  1.6905989e-01 Ad: 1.00e+00 Dobj:  3.0908574e+01 \n",
      "Iter:  2 Ap: 1.00e+00 Pobj:  3.4998523e-01 Ad: 9.00e-01 Dobj:  3.4058426e+00 \n",
      "Iter:  3 Ap: 1.00e+00 Pobj:  1.6203778e+00 Ad: 1.00e+00 Dobj:  3.1483057e+00 \n",
      "Iter:  4 Ap: 1.00e+00 Pobj:  1.6492373e+00 Ad: 1.00e+00 Dobj:  2.4132005e+00 \n",
      "Iter:  5 Ap: 1.00e+00 Pobj:  1.7961213e+00 Ad: 1.00e+00 Dobj:  2.1781021e+00 \n",
      "Iter:  6 Ap: 9.00e-01 Pobj:  1.9795801e+00 Ad: 9.00e-01 Dobj:  2.0177767e+00 \n",
      "Iter:  7 Ap: 9.00e-01 Pobj:  1.9979580e+00 Ad: 1.00e+00 Dobj:  1.9999984e+00 \n",
      "Iter:  8 Ap: 9.00e-01 Pobj:  1.9997958e+00 Ad: 1.00e+00 Dobj:  1.9999984e+00 \n",
      "Iter:  9 Ap: 5.12e-01 Pobj:  1.9998934e+00 Ad: 1.00e+00 Dobj:  2.0000052e+00 \n",
      "Iter: 10 Ap: 1.00e+00 Pobj:  1.9999995e+00 Ad: 1.00e+00 Dobj:  1.9999998e+00 \n",
      "Iter: 11 Ap: 1.00e+00 Pobj:  2.0000000e+00 Ad: 1.00e+00 Dobj:  2.0000000e+00 \n"
     ]
    }
   ],
   "source": [
    "optimize!(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_optimizer(model, with_optimizer(SDPA.Optimizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entering DMUMPS driver with JOB, N, NZ =  -2           0              0\n",
      "Strange behavior : primal < dual :: line 144 in sdpa_solve.cpp\n"
     ]
    }
   ],
   "source": [
    "optimize!(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×2 Array{Float64,2}:\n",
       " 1.0  1.0\n",
       " 1.0  1.0"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value.(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic mode\n",
    "\n",
    "In automatic mode, the caching containing the unbridged model is created in automatic mode, and bridges are automatically applied if `bridge_constraints` is `true`.\n",
    "The cache containing the bridged model is only created if required, e.g. if the model implements `add_variable` and `add_constraint`, it does not need this cache.\n",
    "There are currently three ways to implement copy:\n",
    "* If the solver supports loading the problem incrementally, implement\n",
    "  `add_variable`, `add_constraint` for supported constraints and\n",
    "  [`set`](@ref) for supported attributes and add:\n",
    "  ```julia\n",
    "  function MOI.copy_to(dest::Optimizer, src::MOI.ModelLike; kws...)\n",
    "      return MOI.Utilities.automatic_copy_to(dest, src; kws...)\n",
    "  end\n",
    "  ```\n",
    "  with\n",
    "  ```julia\n",
    "  MOI.Utilities.supports_default_copy_to(model::Optimizer, copy_names::Bool) = true\n",
    "  ```\n",
    "  or\n",
    "  ```julia\n",
    "  MOI.Utilities.supports_default_copy_to(model::Optimizer, copy_names::Bool) = !copy_names\n",
    "  ```\n",
    "  depending on whether the solver support names.\n",
    "  The copy will be carries out by `default_copy_to`.\n",
    "* If the solver does not support loading the problem incrementally, we can either add a custom\n",
    "  implementation of [`copy_to`](@ref);\n",
    "* or implement the Allocate-Load API and do\n",
    "  ```julia\n",
    "  function MOI.copy_to(dest::Optimizer, src::MOI.ModelLike; kws...)\n",
    "      return MOI.Utilities.automatic_copy_to(dest, src; kws...)\n",
    "  end\n",
    "  ```\n",
    "  with\n",
    "  ```julia\n",
    "  MOI.Utilities.supports_allocate_load(model::Optimizer, copy_names::Bool) = true\n",
    "  ```\n",
    "  or\n",
    "  ```julia\n",
    "  MOI.Utilities.supports_allocate_load(model::Optimizer, copy_names::Bool) = !copy_names\n",
    "  ```\n",
    "  depending on whether the solver support names.\n",
    "\n",
    "  Note that even if both writing a custom implementation of [`copy_to`](@ref)\n",
    "  and implementing the [Allocate-Load API](@ref) requires the user to copy the\n",
    "  model from a cache, the [Allocate-Load API](@ref) allows MOI layers to be\n",
    "  added between the cache and the solver which allows transformations to be\n",
    "  applied without the need for additional caching. For instance, with the\n",
    "  proposed [Light bridges](https://github.com/JuliaOpt/MathOptInterface.jl/issues/523),\n",
    "  no cache will be needed to store the bridged model when bridges are used by\n",
    "  JuMP so implementing the [Allocate-Load API](@ref) will allow JuMP to use only\n",
    "  one cache instead of two.\n",
    "\n",
    "Currently, bridges only implement `add_constraint` and not the Allocate-Load API so a cache needs to be used for the bridged model in the two last cases.\n",
    "However, it is planned to implement the Allocate-Load API for bridges (see [Light bridges](https://github.com/JuliaOpt/MathOptInterface.jl/issues/523)).\n",
    "Then by implementing the Allocate-Load API, a solver would not need a cache for the bridged model.\n",
    "\n",
    "To illustrate this, suppose we don't create the cache containing the bridged model.\n",
    "As we can see below, `automatic_copy_to` does not find a method to copy the model from the cache:\n",
    "* It cannot use `default_copy_to` as it is not supported by CSDP and\n",
    "* it cannot use `allocate_load` because it is not supported by the bridges (this should be addressed by [Light bridges](https://github.com/JuliaOpt/MathOptInterface.jl/issues/523))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "ename": "ErrorException",
     "evalue": "Model MathOptInterface.Bridges.LazyBridgeOptimizer{SemidefiniteOptInterface.SOItoMOIBridge{Float64,CSDP.SDOptimizer},MathOptInterface.Utilities.UniversalFallback{MathOptInterface.Bridges.AllBridgedConstraints{Float64}}} does not support copy.",
     "output_type": "error",
     "traceback": [
      "Model MathOptInterface.Bridges.LazyBridgeOptimizer{SemidefiniteOptInterface.SOItoMOIBridge{Float64,CSDP.SDOptimizer},MathOptInterface.Utilities.UniversalFallback{MathOptInterface.Bridges.AllBridgedConstraints{Float64}}} does not support copy.",
      "",
      "Stacktrace:",
      " [1] error(::String, ::String, ::String) at ./error.jl:42",
      " [2] #automatic_copy_to#61(::Bool, ::Function, ::MathOptInterface.Bridges.LazyBridgeOptimizer{SemidefiniteOptInterface.SOItoMOIBridge{Float64,CSDP.SDOptimizer},MathOptInterface.Utilities.UniversalFallback{MathOptInterface.Bridges.AllBridgedConstraints{Float64}}}, ::JuMP._MOIModel{Float64}) at /home/blegat/.julia/dev/MathOptInterface/src/Utilities/copy.jl:19",
      " [3] (::getfield(MathOptInterface.Utilities, Symbol(\"#kw##automatic_copy_to\")))(::NamedTuple{(:copy_names,),Tuple{Bool}}, ::typeof(MathOptInterface.Utilities.automatic_copy_to), ::MathOptInterface.Bridges.LazyBridgeOptimizer{SemidefiniteOptInterface.SOItoMOIBridge{Float64,CSDP.SDOptimizer},MathOptInterface.Utilities.UniversalFallback{MathOptInterface.Bridges.AllBridgedConstraints{Float64}}}, ::JuMP._MOIModel{Float64}) at ./none:0",
      " [4] #copy_to#1(::Base.Iterators.Pairs{Symbol,Bool,Tuple{Symbol},NamedTuple{(:copy_names,),Tuple{Bool}}}, ::Function, ::MathOptInterface.Bridges.LazyBridgeOptimizer{SemidefiniteOptInterface.SOItoMOIBridge{Float64,CSDP.SDOptimizer},MathOptInterface.Utilities.UniversalFallback{MathOptInterface.Bridges.AllBridgedConstraints{Float64}}}, ::JuMP._MOIModel{Float64}) at /home/blegat/.julia/dev/MathOptInterface/src/Bridges/bridgeoptimizer.jl:91",
      " [5] (::getfield(MathOptInterface, Symbol(\"#kw##copy_to\")))(::NamedTuple{(:copy_names,),Tuple{Bool}}, ::typeof(MathOptInterface.copy_to), ::MathOptInterface.Bridges.LazyBridgeOptimizer{SemidefiniteOptInterface.SOItoMOIBridge{Float64,CSDP.SDOptimizer},MathOptInterface.Utilities.UniversalFallback{MathOptInterface.Bridges.AllBridgedConstraints{Float64}}}, ::JuMP._MOIModel{Float64}) at ./none:0",
      " [6] attach_optimizer(::MathOptInterface.Utilities.CachingOptimizer{MathOptInterface.AbstractOptimizer,JuMP._MOIModel{Float64}}) at /home/blegat/.julia/dev/MathOptInterface/src/Utilities/cachingoptimizer.jl:125",
      " [7] optimize!(::MathOptInterface.Utilities.CachingOptimizer{MathOptInterface.AbstractOptimizer,JuMP._MOIModel{Float64}}) at /home/blegat/.julia/dev/MathOptInterface/src/Utilities/cachingoptimizer.jl:161",
      " [8] #optimize!#77(::Bool, ::Bool, ::Function, ::Model, ::Nothing) at /home/blegat/.julia/packages/JuMP/HmKx8/src/optimizer_interface.jl:132",
      " [9] optimize! at /home/blegat/.julia/packages/JuMP/HmKx8/src/optimizer_interface.jl:105 [inlined] (repeats 2 times)",
      " [10] top-level scope at In[102]:9"
     ]
    }
   ],
   "source": [
    "MOI.empty!(optimizer)\n",
    "bridged = MOI.Bridges.full_bridge_optimizer(optimizer, Float64)\n",
    "backend = MOIU.CachingOptimizer(JuMP._MOIModel{Float64}(), MOIU.AUTOMATIC)\n",
    "MOIU.reset_optimizer(backend, bridged)\n",
    "model = direct_model(backend)\n",
    "@variable(model, X[1:2, 1:2], PSD)\n",
    "cref = @constraint(model, X[1, 1] + X[2, 2] ≤ 2)\n",
    "@objective(model, Max, 2X[1, 2])\n",
    "optimize!(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the other hand, Mosek, supports incremental loading of the problem hence it can\n",
    "* either be used with one cache for the unbridged model so that it is possible to change the optimizer (this is what is done in AUTOMATIC and MANUAL modes)\n",
    "* or use no cache."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A JuMP Model\n",
      "Feasibility problem with:\n",
      "Variables: 0\n",
      "Model mode: DIRECT\n",
      "Solver name: Mosek"
     ]
    }
   ],
   "source": [
    "using MosekTools\n",
    "optimizer = Mosek.Optimizer()\n",
    "bridged = MOI.Bridges.full_bridge_optimizer(optimizer, Float64)\n",
    "model = direct_model(bridged)\n",
    "show(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem\n",
      "  Name                   :                 \n",
      "  Objective sense        : max             \n",
      "  Type                   : CONIC (conic optimization problem)\n",
      "  Constraints            : 1               \n",
      "  Cones                  : 0               \n",
      "  Scalar variables       : 3               \n",
      "  Matrix variables       : 1               \n",
      "  Integer variables      : 0               \n",
      "\n",
      "Optimizer started.\n",
      "Presolve started.\n",
      "Linear dependency checker started.\n",
      "Linear dependency checker terminated.\n",
      "Eliminator started.\n",
      "Freed constraints in eliminator : 0\n",
      "Eliminator terminated.\n",
      "Eliminator - tries                  : 1                 time                   : 0.00            \n",
      "Lin. dep.  - tries                  : 1                 time                   : 0.00            \n",
      "Lin. dep.  - number                 : 0               \n",
      "Presolve terminated. Time: 0.00    \n",
      "Problem\n",
      "  Name                   :                 \n",
      "  Objective sense        : max             \n",
      "  Type                   : CONIC (conic optimization problem)\n",
      "  Constraints            : 1               \n",
      "  Cones                  : 0               \n",
      "  Scalar variables       : 3               \n",
      "  Matrix variables       : 1               \n",
      "  Integer variables      : 0               \n",
      "\n",
      "Optimizer  - threads                : 4               \n",
      "Optimizer  - solved problem         : the primal      \n",
      "Optimizer  - Constraints            : 1\n",
      "Optimizer  - Cones                  : 0\n",
      "Optimizer  - Scalar variables       : 1                 conic                  : 0               \n",
      "Optimizer  - Semi-definite variables: 1                 scalarized             : 3               \n",
      "Factor     - setup time             : 0.00              dense det. time        : 0.00            \n",
      "Factor     - ML order time          : 0.00              GP order time          : 0.00            \n",
      "Factor     - nonzeros before factor : 1                 after factor           : 1               \n",
      "Factor     - dense dim.             : 0                 flops                  : 4.60e+01        \n",
      "ITE PFEAS    DFEAS    GFEAS    PRSTATUS   POBJ              DOBJ              MU       TIME  \n",
      "0   2.0e+00  1.0e+00  1.0e+00  0.00e+00   0.000000000e+00   0.000000000e+00   1.0e+00  0.00  \n",
      "1   2.7e-01  1.3e-01  2.5e-01  3.85e-01   1.514460575e+00   1.414954842e+00   1.3e-01  0.00  \n",
      "2   4.3e-03  2.1e-03  2.4e-02  7.97e-01   1.995427246e+00   1.990915247e+00   2.1e-03  0.00  \n",
      "3   5.5e-09  2.7e-09  2.7e-09  9.98e-01   1.999999996e+00   1.999999992e+00   2.7e-09  0.00  \n",
      "Optimizer terminated. Time: 0.00    \n",
      "\n"
     ]
    }
   ],
   "source": [
    "@variable(model, X[1:2, 1:2], PSD)\n",
    "cref = @constraint(model, X[1, 1] + X[2, 2] ≤ 2)\n",
    "@objective(model, Max, 2X[1, 2])\n",
    "optimize!(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×2 Array{Float64,2}:\n",
       " 1.0  1.0\n",
       " 1.0  1.0"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value.(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.1.0",
   "language": "julia",
   "name": "julia-1.1"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
